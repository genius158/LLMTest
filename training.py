import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments
from peft import LoraConfig, get_peft_model
from trl import SFTTrainer
from datasets import load_dataset
import json
from datasets import Dataset

def main():
    model_id = "./models/Qwen3-1.7B"
    output_dir = "./ultra_safe_model"

    # --- 2. MODEL VE TOKENIZER ---
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        torch_dtype=torch.float32,
        device_map="cpu",
        trust_remote_code=True
    )

    # é…ç½®	å‚æ•°é‡	è®­ç»ƒé€Ÿåº¦	æ•ˆæœ	é€‚ç”¨åœºæ™¯
    # ["q_proj", "v_proj"]	æœ€å°	æœ€å¿«	åŸºç¡€é€‚é…	èµ„æºæœ‰é™ï¼Œç®€å•ä»»åŠ¡
    # ["q_proj", "k_proj", "v_proj"]	ä¸­ç­‰	ä¸­ç­‰	æ›´å¥½çš„æ³¨æ„åŠ›è°ƒæ•´	éœ€è¦ç†è§£é•¿ä¸Šä¸‹æ–‡çš„ä»»åŠ¡
    # ["q_proj", "k_proj", "v_proj", "o_proj"]	è¾ƒå¤§	è¾ƒæ…¢	å…¨é¢çš„æ³¨æ„åŠ›è°ƒæ•´	å¤æ‚æ¨ç†ä»»åŠ¡
    # æ‰€æœ‰æ³¨æ„åŠ›å±‚+éƒ¨åˆ†MLPå±‚	æœ€å¤§	æœ€æ…¢	æœ€å…¨é¢çš„å¾®è°ƒ	éœ€è¦æ·±åº¦é¢†åŸŸé€‚åº”çš„ä»»åŠ¡
    peft_config = LoraConfig(
        r=16,  # è¾ƒå°çš„rå€¼å‡å°‘å†…å­˜ä½¿ç”¨
        lora_alpha=32,
        lora_dropout=0.05,
        # target_modules=["q_proj", "v_proj"],
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        task_type="CAUSAL_LM",
    )

    model = get_peft_model(model, peft_config)


    # æ‰“å°å¯è®­ç»ƒå‚æ•°æ•°é‡
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,} | æ€»å‚æ•°: {total_params:,} | ç™¾åˆ†æ¯”: {100 * trainable_params / total_params:.2f}%")

    system_prompt = "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"

    def formatting_prompts_func(examples):
        messages = []
        messages.append({
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"
        })
        for conv in examples["conversations"]:
            messages.append({
                "role": conv["role"],
                "content": conv["content"]
            })
        
        # ä½¿ç”¨tokenizerçš„apply_chat_template
        formatted_text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,  # ä¸è¿›è¡Œtokenizeï¼ŒSFTTrainerä¼šå¤„ç†
            add_generation_prompt=False
        )

        return formatted_text

    # --- è®­ç»ƒ ---
    print("è·å–æ•°æ® ...")
    # ä½¿ç”¨load_datasetçš„æ ‡å‡†æ–¹å¼
    dataset = load_dataset('json', data_files='./lora_identity.jsonl', split='train')
    print(f"Dataset size: {len(dataset)}")
    
    training_args = TrainingArguments(
        output_dir=output_dir,
        overwrite_output_dir=False,
        num_train_epochs=12, #è®­ç»ƒè½®æ¬¡
        per_device_train_batch_size=4,
        gradient_checkpointing=True,
        gradient_accumulation_steps=1,
        learning_rate=1e-4, #é€šç”¨å­¦ä¹ ç‡
        save_steps=50,
        save_total_limit=1,
        weight_decay=0.01, 
        logging_steps=50,
        dataloader_num_workers=0,
        dataloader_pin_memory=False,
        # ç¦ç”¨å¯èƒ½å¼•èµ·é—®é¢˜çš„åŠŸèƒ½
        prediction_loss_only=True,
    )
    
    trainer = SFTTrainer(
        model=model,
        train_dataset=dataset,
        peft_config=peft_config,
        args=training_args,
        formatting_func=formatting_prompts_func,
    )

    print("è®­ç»ƒå¼€å§‹")
    train_result = trainer.train()

    trainer.model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    print(f"ä¿å­˜åˆ°: {output_dir}")

    metrics = train_result.metrics
    print("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!")
    print(f"ğŸ“Š æœ€ç»ˆæŸå¤±: {metrics.get('train_loss', 'N/A')}")
       

if __name__ == '__main__':
    main()