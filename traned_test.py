# basic_validation.py
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import os
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def basic_model_validation(model_path):
    """åŸºç¡€æ¨¡å‹éªŒè¯ï¼šåŠ è½½å’Œç®€å•ç”Ÿæˆæµ‹è¯•"""
    logger.info("ğŸ” å¼€å§‹åŸºç¡€æ¨¡å‹éªŒè¯")
    print("=" * 50)
    
    # 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    required_files = ['pytorch_model.bin', 'config.json', 'tokenizer.json']
    existing_files = os.listdir(model_path)
    logger.info(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {existing_files}")
    
    # 2. åŠ è½½æ¨¡å‹å’Œtokenizer
    try:
        logger.info("ğŸ¤– åŠ è½½å¾®è°ƒåçš„æ¨¡å‹...")
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForCausalLM.from_pretrained(model_path)
        
        # è®¾ç½®è®¾å¤‡
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = model.to(device)
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}")
        logger.info(f"âœ… Tokenizerè¯æ±‡è¡¨å¤§å°: {tokenizer.vocab_size}")
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 3. æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ
    test_prompts = [
        "ä¸¥è´¤ç‚œæ˜¯",
        "èƒ¡å®¹æ˜¯",
        "è‡ªç„¶è¯­è¨€å¤„ç†",
        "å¤§è¯­è¨€æ¨¡å‹å¯ä»¥",
        "å¤§è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢ä¼˜ç§€"
    ]
    
    logger.info("ğŸ¯ æµ‹è¯•æ–‡æœ¬ç”Ÿæˆ...")
    
    for i, prompt in enumerate(test_prompts):
        logger.info(f"\nğŸ“ æµ‹è¯• {i+1}: '{prompt}'")
        
        try:
            # ç¼–ç è¾“å…¥
            inputs = tokenizer(prompt, return_tensors="pt").to(device)
            
            # ç”Ÿæˆæ–‡æœ¬
            with torch.no_grad():
                outputs = model.generate(
                    inputs.input_ids,
                    max_length=len(inputs.input_ids[0]) + 20,  # ç”Ÿæˆ20ä¸ªæ–°token
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=tokenizer.eos_token_id,
                    attention_mask=inputs.attention_mask
                )
            
            # è§£ç ç”Ÿæˆç»“æœ
            generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
            logger.info(f"  ç”Ÿæˆ: {generated}")
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
            continue
    
    return True

def calculate_perplexity(model, tokenizer, test_texts, device="cpu"):
    """è®¡ç®—å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰"""
    logger.info("ğŸ“Š è®¡ç®—å›°æƒ‘åº¦...")
    
    model.eval()
    total_loss = 0
    total_tokens = 0
    
    with torch.no_grad():
        for text in test_texts:
            try:
                # ç¼–ç æ–‡æœ¬
                inputs = tokenizer(text, return_tensors="pt").to(device)
                
                # å‰å‘ä¼ æ’­
                outputs = model(**inputs, labels=inputs.input_ids)
                loss = outputs.loss
                
                # ç´¯è®¡æŸå¤±å’Œtokenæ•°
                total_loss += loss.item() * len(inputs.input_ids[0])
                total_tokens += len(inputs.input_ids[0])
                
            except Exception as e:
                logger.warning(f"âš ï¸ è·³è¿‡æ–‡æœ¬ '{text[:30]}...': {e}")
                continue
    
    if total_tokens > 0:
        perplexity = torch.exp(torch.tensor(total_loss / total_tokens))
        logger.info(f"âœ… å›°æƒ‘åº¦: {perplexity:.2f}")
        return perplexity.item()
    else:
        logger.error("âŒ æ— æ³•è®¡ç®—å›°æƒ‘åº¦")
        return None

if __name__ == "__main__":
    model_path = "./ultra_safe_model"  # ä¿®æ”¹ä¸ºæ‚¨çš„æ¨¡å‹è·¯å¾„
    
    # åŸºç¡€éªŒè¯
    success = basic_model_validation(model_path)
    
    if success:
        logger.info("ğŸ‰ åŸºç¡€éªŒè¯é€šè¿‡!")
    else:
        logger.error("âŒ åŸºç¡€éªŒè¯å¤±è´¥")